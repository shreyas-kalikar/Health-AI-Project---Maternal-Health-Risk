# -*- coding: utf-8 -*-
"""Group11_Health_AI_Project12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sMZUBpEwtv2lxcB2OQScYdlu5fIWCAUM

# **Health AI Project Maternal Health Risk**

# **Group 11.**

# *Shreyas Kalikar, Zhengwei Gu, Tianle Zhu, Xinhao Du, Yan Gu*

# **Summary**
--------------



**Project description**


1. Contextualization: This project focuses on a maternal health risk prediction task based on a Maternal Health Risk dataset collected from the Internet of Medical Devices (IoMT). The dataset's IoMT origin provides a unique opportunity to apply artificial intelligence techniques for modeling, fitting, and predicting in the scenario of digital health. This project aims to identify a minimal subset of IoMT devices most necessary for predicting maternal risk levels using Feature Selection techniques, so that cost for less necessary devices can be saved.

2. Problem: The core problem focuses on optimizing maternal health risk prediction by judiciously selecting a subset of IoMT devices while maintaining predictive accuracy. The challenge lies in striking a balance between accuracy and efficiency in feature selection. This involves not only reducing the number of sensors but doing so without compromising the efficacy of predictive models.

3. Proposed approach: For model training, we experiment with five distinct machine learning models and fine tune each of them by the method of grid search. For feature selection, we adopt a correlation-based method and an iterative approach that examines every possible subset of the given features.

4. Impact: The success of this project will impact patients' wellbeing in two aspects: Firstly, aided by AI, accurate diagnoses regarding their maternal health level can be achieved without human effort. Secondly, cost for maternal healthcare can be reduced due to the fact that some unnecessary IoMT device can be safely discarded.



**Objective:**
The primary objective of the project is to enhance maternal health risk prediction by leveraging the Maternal Health Risk dataset derived from the Internet of Medical Devices (IoMT). The goal is to employ feature selection techniques to identify a minimal subset of IoMT devices that can predict maternal risk levels accurately. This involves optimizing the balance between accuracy and efficiency in predictive models.In the context of this particular dataset, the objective is to carefully choose the most crucial features from the nine available, creating a refined subset for prediction purposes. Also, we will choose some models that can provide relatively better results. The aim is to achieve the highest possible accuracy in the predictions made using this selected subset.


**Dataset:**
The dataset comprises nine health condition related features, all contributing to the classification of patients' maternal health risk levels. Upon scrutinizing the dataset, we identified potential relationships among some features: Notably, weight exhibits correlations with physical health, potentially influencing blood pressure level, blood sugar level, and heart rate. Examining the two features related to blood pressure, we observed that high SystolicBP tends to be accompanied by high DiastolicBP, suggesting a certain correlation between them. Additionally, two features (Body temperatures in F and C) are essentially the same data in different units, so one of them can be dropped before fed into machine learning models.


**Approach:**
We adopt two methods for feature selection and model training:
- A correlation-based feature selection method: We rank all features by their correlations to the target label, so as to get a rough idea which features could be essential and which can be dropped.
- Training and evaluating distinct machine learning models on all possible subsets of available features: We experiment with five types of machine learning models with different levels of complexity: Logistic Regression, K-nearest Neighbor, Support Vector Machine Classifier, Random Forest, and Forward Neural Network. After thoroughly training and fine-tuning each type of models on every subsets of features, we evaluate the models' performance metrics (accuracy score, recall score, F1 score, precision score) and pick the best combination of model and feature subset as our conclusion.

**Conclusions:**
In the project's final phase, our analysis revealed insightful observations regarding the effectiveness of feature selection in maternal health risk prediction. When utilizing a combination of four features — 'Age', 'SystolicBP', 'DiastolicBP', and 'BS' (Blood Sugar) — our models achieved an impressive accuracy of approximately 89%. This indicates that these features, when used together, provide a robust approach for predicting maternal health risks. Interestingly, a slightly reduced number of features, comprising 'Age', 'DiastolicBP', and 'BS' also yielded commendable results, with an accuracy of around 86%.This suggests a flexible approach in feature selection: for optimal accuracy, all four features should be used, but for cost-effective scenarios, the three-feature combination is a viable and efficient alternative.

--------------

# I. Preparation

**Connect to your Google Account:** You are required to use Google Colab. Hence the first thing you will do is connect to your account and mount your landing Google Drive folder.
"""

from google.colab import drive
drive.mount("/content/drive", force_remount=True)

"""### **Importing the necessary libraries and overview of the dataset**

Import all necessary libraries here:
"""

# basic libraries to import
import numpy as np  # For numerical operations
import pandas as pd  # For data manipulation and analysis
import matplotlib.pyplot as plt  # For data visualization
import seaborn as sns
from datetime import datetime
from itertools import combinations
import os

# machine learning libraries to import
from sklearn.preprocessing import StandardScaler, LabelEncoder  # For standardizing features
from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets and splitting training set into training and validation sets
from sklearn.linear_model import LogisticRegression  # For logistic regression modeling
from sklearn.neighbors import KNeighborsClassifier  # For k-nearest neighbors classifier
from sklearn.svm import SVC  # For support vector classification
from sklearn.ensemble import RandomForestClassifier  # For random forest classification
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, precision_recall_fscore_support  # For model evaluation
from keras.models import Sequential
from keras.layers import Dense

"""### **Loading the data**
To load oyur dataset, you need to first upload the dataset to your Google drive. It is a good practice to first create a folder in your drive dedicated to datasets. For instance '/content/drive/Datasets/your-project-dataset.csv'

Create such a folder, then upload your dataset to it.

Then, load the dataset using read_csv() into a datadrame.
"""

def load_feature_list(file_path):
    df = pd.read_csv(file_path, nrows=1)
    return df.columns.to_list()

def load_all_data(data_path='./data'):
    data = pd.read_csv(f'{data_path}/data.csv')
    return data

data = load_all_data('./data')

"""### **Exploratory Data Analysis - Understand and connect with the Dataset**
At this point you need to gain a deep understanding of the data you're working with. Know the format, structure, shape and the type of information the data contains. Use pandas, matplotlib and numpy to interrogate and visualize the dataset to understand its shape, size, contents, distribution and any skewness of its contents,and to also get a feel for its cleanness, completeness, and any other issues.




"""

def explore_data(data):
    print("First few rows:\n")
    print(data.head())
    print("--------------------")
    print("Shape:\n")
    print(data.shape)
    print("--------------------")
    print("Data types:\n")
    print(data.dtypes)
    print("--------------------")
    print("Summary statistics:\n")
    print(data.describe())
    print("--------------------")
    print("Missing values:\n")
    print(data.isnull().sum())
    print("--------------------")

    # Plot histograms for each numerical column
    data.hist(figsize=(10, 10), bins=50, xlabelsize=8, ylabelsize=8)
    plt.tight_layout()
    plt.show()

    # Check the distribution of the 'RiskLevel' column
    print(data['RiskLevel'].value_counts())

    # Plot a pie chart for the 'RiskLevel' column
    data['RiskLevel'].value_counts().plot(kind='pie', figsize=(6, 6))
    plt.show()

explore_data(data)

"""### **OBSERVATIONS:**
- The label column 'Risk Level' are categorical strings - we need to convert it to numeric type so it can be fed into machine leaning models.
- All numeric data fields are distributed across different ranges; It would be necessary to normalize them by scaling values into the same range, to get better performance when applying machine leaning techniques.
- BodyTemp_F and BodyTemp_C columns are highly correlated according to their histograms - we can drop one of them. This naturally makes sense as they are the same data in different units.

# II. Data Preprocessing

## **Choose Your Data Preprocessing Methods:**

Numeric values(or features) in original data can be preprocessed by the methods below. One or more methods can be selected.
1. Standardization: This method involves transforming each value by subtracting the mean and dividing by the standard deviation of the dataset, thus achieving a zero mean and unit variance, commonly termed Z-score normalization.
2. Min-Max Normalization: This method rescales each value by subtracting the minimum value and dividing by the range of the dataset, thereby transforming the data to fit within a specified range, typically 0 to 1.
3. Mean Normalization: Similar to standardization, this method adjusts values to have a zero mean by subtracting the mean and dividing by the range, without altering the standard deviation.
4. Unit Vector Normalization: This approach normalizes data by dividing each value by its vector magnitude, resulting in a dataset where each value has a unit length.

Codes in original data can be preprocessed by the below. However the encoded values should be handled separatedly comparing to numeric values.
- Encode categorical variables using methods like one-hot encoding or label encoding.

Others are considered as below.
- Handle missing data by imputing or removing null values.

Choose appropriate preprocessing methods considering the type of the values. List the methods that you will use providing a short derscription of each.

## Apply your Data Preprocessing Methods:

Implement the chosen preprocessing method on the original data.

Save a deep copy of original data for comparison:
"""

original_data = data.copy(deep=True)

"""Normalize the data by scaling it into the same range:"""

def scale_data(data):
    numeric_cols = data.select_dtypes(include=[np.number]).columns
    scaler = StandardScaler()
    data[numeric_cols] = scaler.fit_transform(data[numeric_cols])
    return data

preprocessed_data = scale_data(data)

"""Encode the labels:"""

def convert_string_to_categorical(data):
    for col in data.columns:
        # Convert label strings to categorical values
        if data[col].dtype == 'object':
            data[col] = pd.Categorical(data[col]).codes
    return data

preprocessed_data = convert_string_to_categorical(preprocessed_data)

"""Drop correlated columns:"""

def drop_correlated_columns(data, correlated_column_names = ["BodyTemp_C"]):
    for correlated_column_name in correlated_column_names:
        try:
            data.drop(correlated_column_name, axis=1, inplace=True)
        except:
            pass
    return data

preprocessed_data = drop_correlated_columns(preprocessed_data)

"""Inspect the preprocessed data a bit:"""

print("First few rows of preprocessed data:\n")
print(preprocessed_data.head())
print("--------------------")

"""## Show your Preprocssed Data:

Show your preprocessed data comparing to the original data
"""

# Compare the first few rows of the original and preprocessed data
print('Original data:\n')
print(original_data.head())
print('--------------------')
print('Preprocessed data:\n')
print(preprocessed_data.head())
print('--------------------')

print("Histograms for the original data:\n")
original_data.hist(figsize=(10, 10), bins=50, xlabelsize=8, ylabelsize=8)
plt.tight_layout()
plt.show()
print("--------------------")

print("Histograms for the preprocessed data:\n")
preprocessed_data.hist(figsize=(10, 10), bins=50, xlabelsize=8, ylabelsize=8)
plt.tight_layout()
plt.show()

"""# III. Preparation of Learning Data

## Split the Data:
Divide the dataset into learning, training and testing datasets.
"""

# Define the size of the train and test datasets
train_size = 0.8
test_size = 0.2

# Set a seed for reproducibility across runs
random_state = 44

train_data, test_data = train_test_split(preprocessed_data, test_size=(1 - train_size), random_state=random_state)

print("Training dataset shape:\n")
print(train_data.shape)
print("--------------------")
print("Testing dataset shape:\n")
print(test_data.shape)
print("--------------------")

pd.DataFrame(train_data).to_csv('data/train.csv', index=False)
pd.DataFrame(test_data).to_csv('data/test.csv', index=False)

"""# IV. Feature Selection

## Feature Selection Methods:

In the feature selection phase, we employed two distinct methods to identify pivotal features:
    
1. Filter Methods: Employ the Correlation-based Feature Selection method, which involves assessing the correlation between features and the target variable to identify the most influential ones.

2. Wrapper Methods: This approach involves evaluating subsets of features by training and testing each kind of proposed model iteratively, ensuring a comprehensive exploration of feature combinations to uncover the most impactful ones.

## Apply Feature Selection Methods:

Implement the chosen feature selection methods on the training data. This involves ranking or scoring features based on their relevance to the target variable.

### Filter Methods:

In the given code, we employed the Correlation-based Feature Selection method to enhance our feature selection process. Initially, we applied label encoding to convert categorical values in the 'RiskLevel' column of the dataset into numerical labels. Next, we separated the data into features (X) and the target variable (y).

The pivotal step involves computing the correlation matrix for all features. This matrix quantifies the relationships between each pair of features in the dataset. To visually interpret these relationships, a heatmap was generated using the Seaborn library, providing an intuitive representation of the strength and direction of correlations. The color intensity in the heatmap indicates the degree of correlation, with warmer colors signifying stronger positive correlations and cooler colors indicating stronger negative correlations.

To conclude the process, the code prints the correlation values sorted in descending order. This list offers insights into how strongly each feature correlates with the target variable ('RiskLevel'). These correlation values play a crucial role in guiding feature selection, helping us identify which features exhibit the most significant relationships with the target variable and are therefore potentially more influential in predictive modeling.
"""

#Correlation-based Feature Selection:
label_encoder = LabelEncoder()
preprocessed_data['RiskLevel'] = label_encoder.fit_transform(preprocessed_data['RiskLevel'])

X = preprocessed_data.drop('RiskLevel', axis=1)
y = preprocessed_data['RiskLevel']

preprocessed_data.head()
correlation_matrix = preprocessed_data.corr()

plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Matrix of Features")
plt.show()
correlation_with_target = correlation_matrix['RiskLevel'].sort_values(ascending=False)
print("correlation with our target is:")
print("-----------------------------------")
correlation_with_target

"""The output chart indicates that the top 5 most important features for predicting 'RiskLevel' are BS (Blood Sugar), DiastolicBP (Diastolic Blood Pressure), Age, SystolicBP (Systolic Blood Pressure), and HeartRate. These features exhibit strong positive correlations with the target variable, suggesting their potential significance in predicting risk levels. This insight can inform feature prioritization for more effective predictive modeling.

### Wrapper Methods:

In light of the relatively lightweight dataset we have and complexity of our proposed machine learning models, here we adopt the second technique - to evaluate all possible subsets of features on all models (plus model-specific fine tuning), compare the results and decide the best feature subset (with minimum number of features while giving the models decent performance).

This is done in the following steps:
1. Generate all $\sum_{k=0}^{n} C(n, k)$ combinations of feature indices, to get all possible subsets of features we have
2. For each of the proposed machine learning models and feature subsets, repeatedly do:

    2.1: Create a list of instances of the current model with different setups, by the method of grid search.

    2.2: Train each model in 2.1 on each of the feature subsets.
    
    2.3: Log the model setups and the current feature subset for later comparison in Step 3.

3. Compare the results by comparing models' performance (accuracy, recall, precision, and F1 score) and draw conclusions.

Get all possible subsets of features:
"""

def get_feature_subsets(min_num_features=2, num_features=8):
    indices = list(range(num_features))
    combinations_list = []
    for r in range(min_num_features, num_features + 1):
        combinations_list.extend(combinations(indices, r))
    return combinations_list

all_feature_subsets = get_feature_subsets()
print("Number of all feature subsets:\n")
print(len(all_feature_subsets))
print("--------------------")
print("All feature subsets:\n")
feature_names = preprocessed_data.columns
for feature_subset in all_feature_subsets:
    print([feature_names[idx] for idx in feature_subset])

"""Based on our research, we propose five types of machine learning models with different levels of complexity - they are: Logistic Regression, K-Nearest Neighbor, Support Vector Machine Classifier, Random Forest, and Forward Neural Network.

Below are some utility functions for generating and training these models. All training logs are saved to a newly generated file in the output folder.
"""

def get_logistic_regression_model():
    return LogisticRegression()

def get_knn_model(n_neighbors=15):
    return KNeighborsClassifier(n_neighbors)

def get_svc_model(kernel='linerar', C=1.0):
    return SVC(kernel=kernel, C=C)

def get_random_forest_model(n_estimators=300, max_depth=10, random_state=0):
    return RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)

def get_knn_model_list_with_grid_search(n_neighbors_list=[15, 20, 25, 30]):
    models = []
    for n_neighbors in n_neighbors_list:
        models.append(
            get_knn_model(
                n_neighbors=n_neighbors
                )
        )
    return models

def get_svc_model_list_with_grid_search(kernel_list=['linear', 'poly', 'rbf', 'sigmoid'], C_list=[1.0, 2.0, 3.0]):
    models = []
    for kernel in kernel_list:
        for C in C_list:
            models.append(
                get_svc_model(
                    kernel=kernel,
                    C=C
                    )
            )
    return models

def get_random_forest_model_list_with_grid_search(n_estimators_list=[100, 200, 300], max_depth_list=[10, 20, 30], random_state_list=[0]):
    models = []
    for n_estimators in n_estimators_list:
        for max_depth in max_depth_list:
            for random_state in random_state_list:
                models.append(
                    get_random_forest_model(
                        n_estimators=n_estimators,
                        max_depth=max_depth,
                        random_state=random_state
                        )
                )
    return models

label_column = 'RiskLevel'
max_num_features = 8
min_num_features = 2

feature_list = load_feature_list('./data/data.csv')

def train_model_on_all_feature_subsets(model, train_data, valid_data, test_data):
    X_train = train_data.drop(label_column, axis=1)
    y_train = train_data[label_column]
    X_valid = valid_data.drop(label_column, axis=1)
    y_valid = valid_data[label_column]
    X_test = test_data.drop(label_column, axis=1)
    y_test = test_data[label_column]

    feature_subset_to_scores = {}

    for i, feature_subset in enumerate(all_feature_subsets):
        cur_X_train = X_train.iloc[:, list(feature_subset)]
        cur_X_valid = X_valid.iloc[:, list(feature_subset)]
        cur_X_test = X_test.iloc[:, list(feature_subset)]


        print(f"training {model} with subset of features {[feature_list[i] for i in feature_subset]}, progress: {i+1}/{len(all_feature_subsets)}")

        model.fit(cur_X_train, y_train)

        # Validate the model
        valid_predictions = model.predict(cur_X_valid)
        valid_scores = (accuracy_score(y_valid, valid_predictions), precision_score(y_valid, valid_predictions, average='micro'), recall_score(y_valid, valid_predictions, average='micro'), f1_score(y_valid, valid_predictions, average='micro'))

        # Test the model
        test_predictions = model.predict(cur_X_test)
        test_scores = (accuracy_score(y_test, test_predictions), precision_score(y_test, test_predictions, average='micro'), recall_score(y_test, test_predictions, average='micro'), f1_score(y_test, test_predictions, average='micro'))

        feature_subset_to_scores[feature_subset] = (valid_scores, test_scores)

    # print top 10 scores and feature subsets
    top10_feature_subset_and_scores = sorted(feature_subset_to_scores.items(), key=lambda x: x[1][1], reverse=True)[0:10]
    print("Finished training, Top 10 scores and feature subsets:\n", top10_feature_subset_and_scores)
    log_train_results(model, top10_feature_subset_and_scores)

    return top10_feature_subset_and_scores

def train_list_of_models_on_all_feature_subsets(model_list, train_data, valid_data, test_data):
    for i, model in enumerate(model_list):
        print(f"training model {model}, progress {i+1}/{len(model_list)}")
        train_model_on_all_feature_subsets(model, train_data, valid_data, test_data)

def log_train_results(model, indices_and_scores):
    # indices_and_scores is a list of tuples, each tuple contains a feature subset and its corresponding scores
    # e.g. [(feature subset, (valid_scores, test_scores)), ...]
    # valid_scores and test_scores are tuples of (accuracy_score, precision_score, recall_score, f1_score)

    feature_indices = []
    feature_names = []
    val_accuracy_scores = []
    test_accuracy_scores = []
    val_precision_scores = []
    test_precision_scores = []
    val_recall_scores = []
    test_recall_scores = []
    val_f1_scores = []
    test_f1_scores = []

    for v in indices_and_scores:
        feature_indices.append(v[0])
        feature_names.append([feature_list[i] for i in v[0]])
        val_accuracy_scores.append(v[1][0][0])
        test_accuracy_scores.append(v[1][1][0])
        val_precision_scores.append(v[1][0][1])
        test_precision_scores.append(v[1][1][1])
        val_recall_scores.append(v[1][0][2])
        test_recall_scores.append(v[1][1][2])
        val_f1_scores.append(v[1][0][3])
        test_f1_scores.append(v[1][1][3])

    df = pd.DataFrame({
        'Model': str(model),
        'Feature Indices': feature_indices,
        'Feature Names': feature_names,
        'Validation Accuracy Scores': val_accuracy_scores,
        'Test Accuracy Scores': test_accuracy_scores,
        'Validation Precision Scores': val_precision_scores,
        'Test Precision Scores': test_precision_scores,
        'Validation Recall Scores': val_recall_scores,
        'Test Recall Scores': test_recall_scores,
        'Validation F1 Scores': val_f1_scores,
        'Test F1 Scores': test_f1_scores
    })

    timestamp = datetime.now().strftime('%m%d_%H%M')
    # name the output file with the best validation accuracy score, followed by the test accuracy score, model name, and the timestamp
    file_name = f'output/{indices_and_scores[0][1][0][0]:.2f}-{indices_and_scores[0][1][1][0]:.2f}-{str(model)}-{timestamp}.csv'

    df.to_csv(file_name, index=False)

"""## Evaluate Models Performance:

Train your machine learning models using the selected features and evaluate their performance on the testing set. Measure metrics such as accuracy, precision, recall, and F1 score.

Use a portion of train set as validation set. This validation set is used for evaluating and picking the best models and feature subsets.
"""

train_data, valid_data = train_test_split(train_data, test_size=0.1, random_state=random_state)

"""Train and evaluate a logistic regression model on all feature subsets, as our baseline. Here we use logistic regression since it's the simplest yet working machine learning model, and we can use it as a starting point for further model / feature subset exploration."""

logistic_regression_model = get_logistic_regression_model()
train_list_of_models_on_all_feature_subsets([logistic_regression_model], train_data, valid_data, test_data)

"""Train and fine tune a K-Nearest Neighbors model with grid search on all feature subsets, and evaluate the model."""

knn_model_list = get_knn_model_list_with_grid_search(n_neighbors_list=[2, 3, 5, 10, 15, 20, 25, 30, 40, 50, 100])
train_list_of_models_on_all_feature_subsets(knn_model_list, train_data, valid_data, test_data)

"""Train and fine tune a support vector machine classifier with grid search on all feature subsets, and evaluate the model."""

svc_model_list = get_svc_model_list_with_grid_search(kernel_list=['linear', 'poly', 'rbf', 'sigmoid'], C_list=[1.0, 2.0, 3.0])
train_list_of_models_on_all_feature_subsets(svc_model_list, train_data, valid_data, test_data)

"""Train and fine tune a random forest model with grid search on all feature subsets, and evaluate the model."""

random_forest_model_list = get_random_forest_model_list_with_grid_search(
    n_estimators_list=[100, 200, 300],
    max_depth_list=[10, 20, 30],
    random_state_list=[0]
    )
train_list_of_models_on_all_feature_subsets(random_forest_model_list, train_data, valid_data, test_data)

"""Train and fine tune a two-layer neural network model on all feature subsets, and evaluate the model.

The training process is slightly different from other models as the input size for a neural network is fixed - we need to adjust this based on num of features we are using.
"""

max_features = 8

def get_two_layer_neural_network_model(input_size = 8, layer_1_width=32, layer_1_activation='relu', layer_2_width=16, layer_2_activation='relu', optimizer='adam', loss='sparse_categorical_crossentropy'):
    model = Sequential()
    model.add(Dense(layer_1_width, activation=layer_1_activation, input_shape=(input_size,)))
    model.add(Dense(layer_2_width, activation=layer_2_activation))
    model.add(Dense(3, activation='softmax'))
    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])
    return model

def train_neural_network_on_all_feature_subsets(train_data, valid_data, test_data):
    encoder = LabelEncoder()

    X_train = train_data.drop(label_column, axis=1)
    y_train = train_data[label_column]
    y_train = encoder.fit_transform(y_train)

    X_valid = valid_data.drop(label_column, axis=1)
    y_valid = valid_data[label_column]
    y_valid = encoder.transform(y_valid)

    X_test = test_data.drop(label_column, axis=1)
    y_test = test_data[label_column]
    y_test = encoder.transform(y_test)

    feature_subset_to_scores = {}

    for i, feature_subset in enumerate(all_feature_subsets):
        cur_X_train = X_train.iloc[:, list(feature_subset)]
        cur_X_valid = X_valid.iloc[:, list(feature_subset)]
        cur_X_test = X_test.iloc[:, list(feature_subset)]


        print(f"training neural network with sub set of features {feature_subset}, progress: {i+1}/{len(all_feature_subsets)}")

        nn = get_two_layer_neural_network_model(input_size=len(feature_subset))

        nn.fit(cur_X_train, y_train, epochs=100, validation_data=(cur_X_valid, y_valid), verbose=0)

        # Evaluate the model on the validation set
        y_valid_pred = nn.predict(cur_X_valid, verbose=0)
        y_valid_pred = np.argmax(y_valid_pred, axis=1)
        print("Validation Set Metrics:")
        valid_precision, valid_recall, valid_f1_score, _ = precision_recall_fscore_support(y_valid, y_valid_pred)
        _, valid_accuracy = nn.evaluate(cur_X_valid, y_valid, verbose=0)
        print("Validation Accuracy", valid_accuracy, "Validation Precision:", np.mean(valid_precision), "Validation Recall:", np.mean(valid_recall), "Validation F1 Score:", np.mean(valid_f1_score))
        valid_scores = (valid_accuracy, np.mean(valid_precision), np.mean(valid_recall), np.mean(valid_f1_score))

        # Evaluate the model on the test set
        y_test_pred = nn.predict(cur_X_test, verbose=0)
        y_test_pred = np.argmax(y_test_pred, axis=1)
        print("Test Set Metrics:")
        test_precision, test_recall, test_f1_score, _ = precision_recall_fscore_support(y_test, y_test_pred)
        _, test_accuracy = nn.evaluate(cur_X_test, y_test, verbose=0)
        print("Test Accuracy", test_accuracy, "Test Precision:", np.mean(test_precision), "Test Recall:", np.mean(test_recall), "Test F1 Score:", np.mean(test_f1_score))
        test_scores = (test_accuracy, np.mean(test_precision), np.mean(test_recall), np.mean(test_f1_score))

        feature_subset_to_scores[feature_subset] = (valid_scores, test_scores)

    # print top 10 scores and feature index combinations
    top10_feature_subset_and_scores = sorted(feature_subset_to_scores.items(), key=lambda x: x[1][1], reverse=True)[0:10]
    print("Finished training, Top 10 scores and feature index combinations:\n", top10_feature_subset_and_scores)
    log_train_results("TwoLayerNeuralNetwork", top10_feature_subset_and_scores)
    return top10_feature_subset_and_scores

train_neural_network_on_all_feature_subsets(train_data, valid_data, test_data)

"""## Compare Models Performance:

Provide a comparative analysis of the relative performance of the used models.

We compare all the experimented (model, feature_subset) tuples to decide a best combination, where the model gives decent performance while using as few features as possible.

The comparison is primarily based on accuracy score on validation set, and uses <recall score, F1 score, precision score>(sorted by order) as tie breakers. Because accurately predicting patients' conditions and successfully identifying more high-risk patients are the most important metrics in this digital health scenario.

We merged all the model training results into one csv file and sorted them to make the results more clear and intuitive.
"""

outputs = sorted(os.listdir('./output'), reverse=True)

# collect all experiment results
dfs = []
for output in outputs:
    df = pd.read_csv(f'./output/{output}')
    dfs.append(df)

merged_df = pd.concat(dfs)

# sort by valid accuracy score, valid recall score, valid precision score, and valid f1 score
df_sorted = merged_df.sort_values(by=['Validation Accuracy Scores', 'Validation Recall Scores', 'Validation F1 Scores', 'Validation Precision Scores'], ascending=False)

print(df_sorted.head(10))
df_sorted.to_csv('output/final_result.csv', index=False)

"""# **VI. Conclusion and Final Recommendations**

Based on our experiment results, we can draw the following conclusions:
- A random forest model with its max depth set to 30 is most suitable for this task - it gives 89% accuracy score and 88% recall score on test set, which are quite impressive given the limited amount of data we have. We believe it would perform even better if more training data can be collected.
- With the best model described above, surprisingly, it gives the best performance when trained on only four features: Age, Systolic BP, Diastolic BP, and Blood Sugar level. This suggests that the rest four features contribute less to the prediction of target label. So a reduction of cost on IoMT devices for these features is totally feasible.
- The best model, when trained on an even smaller subset of features (Age, Diastolic BP, and Blood Sugar level), can also give us a decent accuracy score of 86%. In light of this observation, we would like to propose that: if a slight loss of accuracy is tolerable and cost for collecting the extra feature is significant, we can even sacrifice the accuracy a bit for cost control, and make up for the accuracy loss by other means (e.g. collecting more training data).
- Neural network is not a panacea for any machine leaning task. We were expecting a neural network to perform as the best, until we found the random forest always gives better results, no matter how hard we tune the neural network's parameters.

Our methods outweigh other feature selection methods for several reasons:
- We used correlation-based feature selection, which efficiently identifies the most relevant features from an IoMT dataset. This approach gives us a rough idea of the relevance of the features and ensures that the model is not overburdened with irrelevant or redundant data, which can be a common problem in datasets with a large number of variables.
- We iterated through all possible subsets of available features. This might sound like a brute-force and naive approach at first glance, but it does make sense. Because we have few features (only 8 of them if dropping the 'duplicate' one), and the given dataset only consists of ~1000 data points.
- The models we experimente d with are pretty much lightweight so training them on modern CPU/GPU is relatively effortless.

So a thorough search through all feature subset is doable in our case, and it can definitely find the most ideal subset because of its exhaustiveness. Meanwhile, it's also worth noting that our approach might not be feasible if either of these conditions no longer holds. In such cases we'd better to resort to other statistic methods that examine various charsticriics of all features, to decide significance of each feature.
"""